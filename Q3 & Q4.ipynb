{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Region Segmentation Using Traditional Techniques"
      ],
      "metadata": {
        "id": "mIun2HtY-5CC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_path = '1.zip'  # Replace with your zip file name\n",
        "extract_path = \"image\"  # Folder where the dataset will be extracted\n",
        "\n",
        "# Get the absolute path to the zip file\n",
        "zip_path = os.path.abspath(zip_path)\n",
        "\n",
        "# Check if the file exists before attempting to open it\n",
        "if os.path.exists(zip_path):\n",
        "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "        zip_ref.extractall(extract_path)\n",
        "\n",
        "    print(\"Dataset extracted successfully!\")\n",
        "else:\n",
        "    print(f\"Error: Zip file not found at {zip_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfSc3fRx1Tlp",
        "outputId": "479f328c-dec8-4062-aa3a-91abcbc68470"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset extracted successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Folder paths\n",
        "input_folder = 'image/MSFD/1/face_crop'\n",
        "output_folder = 'image/MSFD/1/face_crop_segmentation'\n",
        "\n",
        "# Create output folder if it doesn't exist\n",
        "if not os.path.exists(output_folder):\n",
        "    os.makedirs(output_folder)\n",
        "\n",
        "# Get the list of images in the input folder\n",
        "image_files = [f for f in os.listdir(input_folder) if f.endswith('.jpg') or f.endswith('.png')]\n",
        "\n",
        "# Get the list of ground truth files in the segmentation folder\n",
        "segmentation_files = [f for f in os.listdir(output_folder) if f.endswith('.jpg') or f.endswith('.png')]\n",
        "\n",
        "# Track deleted and matched files\n",
        "deleted_images = 0\n",
        "matched_images = []\n",
        "\n",
        "# Check for matching filenames, remove unmatched files from the input folder\n",
        "for image_file in image_files:\n",
        "    if image_file not in segmentation_files:\n",
        "        image_path = os.path.join(input_folder, image_file)\n",
        "        os.remove(image_path)\n",
        "        deleted_images += 1\n",
        "    else:\n",
        "        matched_images.append(image_file)\n",
        "\n",
        "print(f\"Deleted {deleted_images} images due to no matching segmentation file.\")\n",
        "print(f\"{len(matched_images)} images have matching segmentation files.\")\n",
        "\n",
        "# Function to apply region-based segmentation using thresholding\n",
        "def segment_image(image_path):\n",
        "    image = cv2.imread(image_path)\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Thresholding\n",
        "    _, thresholded = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    return thresholded\n",
        "\n",
        "# Function to calculate IoU\n",
        "def calculate_iou(pred_mask, gt_mask):\n",
        "    # Resize predicted mask to match ground truth dimensions\n",
        "    pred_mask = cv2.resize(pred_mask, (gt_mask.shape[1], gt_mask.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "    pred_mask = (pred_mask > 127).astype(np.uint8)  # Convert to binary\n",
        "    gt_mask = (gt_mask > 127).astype(np.uint8)\n",
        "\n",
        "    intersection = np.logical_and(pred_mask, gt_mask)\n",
        "    union = np.logical_or(pred_mask, gt_mask)\n",
        "\n",
        "    if np.sum(union) == 0:\n",
        "        return 0.0  # Avoid division by zero\n",
        "\n",
        "    return np.sum(intersection) / np.sum(union)\n",
        "\n",
        "# Process images and calculate IoU\n",
        "iou_values = []\n",
        "count_above_0_5 = 0  # Counter for images with IoU > 0.5\n",
        "\n",
        "for image_file in matched_images:\n",
        "    image_path = os.path.join(input_folder, image_file)\n",
        "    gt_path = os.path.join(output_folder, image_file)  # Ground truth path\n",
        "\n",
        "    if os.path.exists(image_path) and os.path.exists(gt_path):\n",
        "        gt_image = cv2.imread(gt_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        # Apply segmentation\n",
        "        thresholded = segment_image(image_path)\n",
        "\n",
        "        # Calculate IoU after resizing\n",
        "        iou_thresholded = calculate_iou(thresholded, gt_image)\n",
        "        iou_values.append(iou_thresholded)\n",
        "\n",
        "        # Count how many images have IoU > 0.5\n",
        "        if iou_thresholded > 0.5:\n",
        "            count_above_0_5 += 1\n",
        "\n",
        "# Calculate and print the average IoU\n",
        "if iou_values:\n",
        "    average_iou = np.mean(iou_values)\n",
        "    print(f\"Average IoU for thresholding (all images): {average_iou:.4f}\")\n",
        "    print(f\"Number of images with IoU > 0.5: {count_above_0_5}\")\n",
        "else:\n",
        "    print(\"No valid IoU values calculated.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50T8r217s-Ml",
        "outputId": "2d7c7dea-90f2-4d19-8c88-dca08a038ae5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleted 1 images due to no matching segmentation file.\n",
            "9382 images have matching segmentation files.\n",
            "Average IoU for thresholding (all images): 0.2674\n",
            "Number of images with IoU > 0.5: 1434\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mask Segmentation Using U-Net"
      ],
      "metadata": {
        "id": "k0mw1C2z_Cja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6c51q0ntGJv",
        "outputId": "2ca019df-2e47-4804-b207-2cb54c67993b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, in_channels=1, out_channels=1):\n",
        "        super(UNet, self).__init__()\n",
        "\n",
        "        def conv_block(in_c, out_c):\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(in_c, out_c, kernel_size=3, padding=1),\n",
        "                nn.BatchNorm2d(out_c),  # BatchNorm speeds up training\n",
        "                nn.LeakyReLU(inplace=True),\n",
        "                nn.Conv2d(out_c, out_c, kernel_size=3, padding=1),\n",
        "                nn.BatchNorm2d(out_c),\n",
        "                nn.LeakyReLU(inplace=True)\n",
        "            )\n",
        "\n",
        "        self.encoder1 = conv_block(in_channels, 16)  # Reduced from 64 to 16\n",
        "        self.encoder2 = conv_block(16, 32)           # Reduced from 128 to 32\n",
        "        self.encoder3 = conv_block(32, 64)           # Reduced from 256 to 64\n",
        "\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.bottleneck = conv_block(64, 128)        # Reduced from 512 to 128\n",
        "\n",
        "        self.upconv3 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
        "        self.decoder3 = conv_block(128, 64)\n",
        "        self.upconv2 = nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2)\n",
        "        self.decoder2 = conv_block(64, 32)\n",
        "        self.upconv1 = nn.ConvTranspose2d(32, 16, kernel_size=2, stride=2)\n",
        "        self.decoder1 = conv_block(32, 16)\n",
        "\n",
        "        self.final_conv = nn.Conv2d(16, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        e1 = self.encoder1(x)\n",
        "        e2 = self.encoder2(self.pool(e1))\n",
        "        e3 = self.encoder3(self.pool(e2))\n",
        "\n",
        "        b = self.bottleneck(self.pool(e3))\n",
        "\n",
        "        d3 = self.decoder3(torch.cat([self.upconv3(b), e3], dim=1))\n",
        "        d2 = self.decoder2(torch.cat([self.upconv2(d3), e2], dim=1))\n",
        "        d1 = self.decoder1(torch.cat([self.upconv1(d2), e1], dim=1))\n",
        "\n",
        "        return torch.sigmoid(self.final_conv(d1))\n",
        "\n",
        "# Initialize model on CPU\n",
        "model = UNet().to(device)\n",
        "print(\"U-Net Model Initialized Successfully on CPU\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1is36NDJ3zwL",
        "outputId": "b2db3b5c-946d-4a7a-b160-188e5f051e8b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "U-Net Model Initialized Successfully on CPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import multiprocessing\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Dataset Class\n",
        "class SegmentationDataset(Dataset):\n",
        "    def __init__(self, image_dir, mask_dir):\n",
        "        self.image_dir = image_dir\n",
        "        self.mask_dir = mask_dir\n",
        "        self.image_files = [f for f in os.listdir(image_dir) if f.endswith('.jpg') or f.endswith('.png')]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.image_dir, self.image_files[idx])\n",
        "        mask_path = os.path.join(self.mask_dir, self.image_files[idx])\n",
        "\n",
        "        image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        # Resize to 32x32 for faster training\n",
        "        image = cv2.resize(image, (32, 32)) / 255.0\n",
        "        mask = cv2.resize(mask, (32, 32)) / 255.0\n",
        "\n",
        "        image = torch.tensor(image, dtype=torch.float32).unsqueeze(0)\n",
        "        mask = torch.tensor(mask, dtype=torch.float32).unsqueeze(0)\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "# Get available CPU cores\n",
        "num_workers = min(2, multiprocessing.cpu_count())  # Avoid system overload\n",
        "\n",
        "# Load dataset\n",
        "image_dir = \"image/MSFD/1/face_crop\"\n",
        "mask_dir = \"image/MSFD/1/face_crop_segmentation\"\n",
        "dataset = SegmentationDataset(image_dir, mask_dir)\n",
        "\n",
        "# Optimized DataLoader for CPU\n",
        "dataloader = DataLoader(\n",
        "    dataset, batch_size=2, shuffle=True,\n",
        "    num_workers=num_workers, pin_memory=False  # No pin_memory for CPU\n",
        ")\n",
        "\n",
        "print(f\"Dataset Loaded: {len(dataset)} images\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNGinFw64bPz",
        "outputId": "93ba211c-c47b-4cee-8e6f-1daec790ea36"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Loaded: 9382 images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "def train_unet(model, dataloader, criterion, optimizer, device, epochs=5):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss = 0\n",
        "        for images, masks in dataloader:\n",
        "            images, masks = images.to(device), masks.to(device)\n",
        "\n",
        "            optimizer.zero_grad()  # Reset gradients\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, masks)\n",
        "\n",
        "            loss.backward()  # Compute gradients\n",
        "            optimizer.step()  # Update model weights\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss/len(dataloader):.4f}\")\n",
        "\n",
        "# Initialize Loss and Optimizer\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
        "\n",
        "# Train the model on CPU\n",
        "train_unet(model, dataloader, criterion, optimizer, device=\"cpu\", epochs=5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Co54-t4Q4tg6",
        "outputId": "00360133-c58c-4203-f4e1-89360ad184a8"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 0.1621\n",
            "Epoch [2/5], Loss: 0.1425\n",
            "Epoch [3/5], Loss: 0.1355\n",
            "Epoch [4/5], Loss: 0.1294\n",
            "Epoch [5/5], Loss: 0.1266\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def evaluate(model, dataloader, device):\n",
        "    model.eval()\n",
        "    iou_values = []\n",
        "    dice_values = []\n",
        "    with torch.no_grad():\n",
        "        for images, masks in dataloader:\n",
        "            images, masks = images.to(device), masks.to(device)\n",
        "            outputs = model(images)\n",
        "\n",
        "            pred_masks = (outputs > 0.5).float()\n",
        "\n",
        "            intersection = (pred_masks * masks).sum()\n",
        "            union = (pred_masks + masks).sum() - intersection\n",
        "            dice = (2. * intersection) / (pred_masks.sum() + masks.sum())\n",
        "\n",
        "            if union > 0:\n",
        "                iou = intersection / union\n",
        "                iou_values.append(iou.item())\n",
        "            dice_values.append(dice.item())\n",
        "\n",
        "    print(f\"Average IoU: {np.mean(iou_values):.4f}\")\n",
        "    print(f\"Average Dice Score: {np.mean(dice_values):.4f}\")\n",
        "\n",
        "# Evaluate Model\n",
        "evaluate(model, dataloader, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNzBfyc44v9w",
        "outputId": "afdda179-3c3f-4767-b19a-9c7ce829447d"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average IoU: 0.8589\n",
            "Average Dice Score: 0.9218\n"
          ]
        }
      ]
    }
  ]
}